


# Importing Libraries
from textblob import TextBlob
import pandas as pd
import os
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib
import nltk
import nltk
import re
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
from collections import Counter
sns.set()





# Creating Path
path = r'C:\Users\anush\20th_Century'


# Loading the twentieth-century data from the CSV file
countries_data = pd.read_csv(os.path.join(path, 'countries_list_20th_century_1.5.csv'), index_col = False)

# Displaying the first few rows to verify the content
countries_data.head()


# Dropping 'Unnamed: 0' Column
countries_data = countries_data.drop(columns=['Unnamed: 0'])
countries_data.head()


import requests
from bs4 import BeautifulSoup

# Fetch the countries list from the provided Wikipedia link
url = "https://simple.m.wikipedia.org/wiki/List_of_countries"
response = requests.get(url)
soup = BeautifulSoup(response.content, 'html.parser')

# Extract country names from the list (assuming they are in <li> tags)
countries = [li.text for li in soup.find_all('li') if li.a]

# Print a sample of countries to verify
print(countries[:10])





# Tokenization and Word Frequency Plotting

# Tokenize the text into words using NLTK
from nltk.tokenize import word_tokenize
words = word_tokenize(text)

# Count the frequency of each word
from collections import Counter
word_freq = Counter(words)

# Get the 10 most common words
most_common_words = word_freq.most_common(10)

# Plot the 10 most common words using matplotlib and seaborn
plt.figure(figsize=(10, 5))
sns.barplot(x=[word for word, freq in most_common_words], y=[freq for word, freq in most_common_words])
plt.title('Top 10 Most Common Words')
plt.xlabel('Words')
plt.ylabel('Frequency')
plt.xticks(rotation=45)
plt.show()



