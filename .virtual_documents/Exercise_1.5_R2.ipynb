


from textblob import TextBlob 
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib
import nltk
import re
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
from collections import Counter
sns.set()





myfile = open('Key_Events_20th_Century.txt', encoding='utf-8') 


# Import txt file
with open('Key_Events_20th_Century.txt', 'r', errors='ignore') as file:
    data = file.read().replace('\n', '')


# Clean text using re.sub
cleaned_text = re.sub(r'[^\w\s]', '', data.lower())


# Sentence tokenization 
from nltk.tokenize import sent_tokenize
tokenized_sent = sent_tokenize(cleaned_text)
print(tokenized_sent)


# Word tokenization
from nltk.tokenize import word_tokenize
tokenized_word = word_tokenize(cleaned_text)
print(tokenized_word)


# Create frequency distribution
from nltk.probability import FreqDist
dist_words = FreqDist(tokenized_word)
print(dist_words)


top_10_words = dist_words.most_common(10)


top_10_words


# Convert to DataFrame for plotting
df_top_10 = pd.DataFrame(top_10_words, columns=["Word", "Frequency"])

# Create a bar chart
plt.figure(figsize=(10, 6))
sns.barplot(x="Frequency", y="Word", data=df_top_10, palette="coolwarm")
plt.title("Top 10 Most Common Words (Including Stop Words and Punctuation)")
plt.xlabel("Frequency")
plt.ylabel("Words")
plt.tight_layout()
plt.show()





# Defining stopwords
from nltk.corpus import stopwords
stop_words = set(stopwords.words("english"))
print(stop_words)


# Removing stopwords in words
filtered_words = [] # creates an empty list
for word in tokenized_word:
    if word not in stop_words:
        filtered_words.append(word)


filtered_words


# Create a new FreqDist for filtered_words
filtered_dist_words = FreqDist(filtered_words)
print(filtered_dist_words)


# Get the 10 most common words after filtering
top_10_filtered = filtered_dist_words.most_common(10)


top_10_filtered


# Convert to DataFrame for visualization
df_top_10_filtered = pd.DataFrame(top_10_filtered, columns=["Word", "Frequency"])

# Plot the bar chart
plt.figure(figsize=(10, 6))
sns.barplot(x="Frequency", y="Word", data=df_top_10_filtered, palette="viridis")
plt.title("Top 10 Most Common Words (Excluding Stop Words and Punctuation)")
plt.xlabel("Frequency")
plt.ylabel("Words")
plt.tight_layout()
plt.show()


filtered_dist_words


# Substitute all punctuation marks with a space 
sans_punc = re.sub("[^a-zA-Z]",  # Search for all non-letters
                          " ",          # Replace all non-letters with spaces
                          str(filtered_words))


sans_punc


# Word tokenization
tokenized_word_2 = word_tokenize(sans_punc)
print(tokenized_word_2)


# Create a new FreqDist
filtered_dist_words_2 = FreqDist(tokenized_word_2)


# Get the 10 most common words after filtering
top_10_filtered_2 = filtered_dist_words_2.most_common(10)


top_10_filtered_2


# Convert to DataFrame for visualization
df_top_10_filtered_2 = pd.DataFrame(top_10_filtered_2, columns=["Word", "Frequency"])

# Plot the bar chart
plt.figure(figsize=(10, 6))
sns.barplot(x="Frequency", y="Word", data=df_top_10_filtered_2, palette="viridis")
plt.title("Top 10 Most Common Words (Excluding Stop Words and Punctuation)")
plt.xlabel("Frequency")
plt.ylabel("Words")
plt.tight_layout()
plt.show()








new_stopwords = ["And", "Then", 'n', 't', 's', 'The']


filtered = []
for word in tokenized_word_2:
    if word not in new_stopwords:
        filtered.append(word)


%%time
text = TextBlob(str(filtered))


text


tags_list = text.tags


tags_list


df_text = pd.DataFrame(tags_list)
df_text.columns = ['Words', "Word type"]


df_text.head()


df_t = df_text.groupby('Word type').count().reset_index()


df_t.head()


top_10_tags = df_t.nlargest(10, 'Words')


top_10_tags


plt.figure(figsize = (10, 5))
with sns.dark_palette("xkcd:blue", 10):
    sns.barplot(x = "Words", y = "Word type",
    saturation = 0.9, data = top_10_tags).set_title("Top 10 POS Tags in the Article")








df = df_text[(df_text['Word type'] == "NN") | (df_text['Word type'] == "NNS") | (df_text['Word type'] == "NNP")]
df.columns = ["Word", "Occurences"]
x = df.groupby('Word').count().reset_index()
y = x.sort_values(by = ['Occurences'], ascending=False)
top_15_nouns = y.nlargest(15, 'Occurences')


top_15_nouns


plt.figure(figsize=(12, 6))
with sns.dark_palette("xkcd:blue", 15):
    sns.barplot(x="Word", y="Occurences",
    saturation=0.9, data = top_15_nouns).set_title("Key Events of the 20th Century - most frequently used nouns")
plt.xticks(rotation=45)
plt.tight_layout()





df = df_text[df_text['Word type'].str.startswith("VB")]
df.columns = ["Word", "Occurences"]
x = df.groupby('Word').count().reset_index()
y = x.sort_values(by = ['Occurences'], ascending=False)
top_15_verbs = y.nlargest(15, 'Occurences')


top_15_verbs


plt.figure(figsize = (12, 6))
with sns.dark_palette("xkcd:blue", 15):
    sns.barplot(x = "Word", y = "Occurences",
    saturation = 0.9, data = top_15_verbs).set_title("Key Events of the 20th Century - most frequently used verbs")
    plt.xticks(rotation=45)
    plt.tight_layout()





df = df_text[df_text['Word type'].str.startswith("JJ")]
df.columns = ["Word", "Occurences"]
x = df.groupby('Word').count().reset_index()
y = x.sort_values(by=['Occurences'], ascending=False)
top_15_adjectives = y.nlargest(15, 'Occurences')


top_15_adjectives


plt.figure(figsize=(12, 6))
with sns.dark_palette("xkcd:blue", 15):
    sns.barplot(x="Word", y="Occurences",
    saturation=0.9, data=top_15_adjectives).set_title("Key Events of the 20th Century - most frequently used adjectives")
    plt.xticks(rotation=45)
    plt.tight_layout()








# Creating Path
path = r'C:\Users\anush\20th_Century'


import os
# Loading the twentieth-century data from the CSV file
countries_data = pd.read_csv(os.path.join(path, 'countries_list_20th_century_1.5.csv'), index_col = False)

# Displaying the first few rows to verify the content
countries_data.head()


# Dropping 'Unnamed: 0' Column
countries_data = countries_data.drop(columns=['Unnamed: 0'])
countries_data.head()


# Clean up the country names column and convert it to a list
countries_list = countries_data['country_name'].str.strip().str.lower().tolist()


# Import txt file
with open('Key_Events_20th_Century.txt', 'r', errors='ignore') as file:
    text = file.read().lower()


# Tokenize the text
dist_words_3 = word_tokenize(text)


# Convert the tokenized list into a single string
listToStr = ' '.join([str(elem).lower() for elem in dist_words_3])


# Clean the tokenized words from unwanted characters and count occurrences
all_counts = Counter(re.sub(r'\W+', ' ', listToStr).split())


# Replace specific country name aliases if necessary
country_mentions = {country: all_counts.get(country, 0) for country in countries_list}

# Convert the dictionary to a DataFrame
country_mentions_df = pd.DataFrame(list(country_mentions.items()), columns=['Country', 'Mentions']).sort_values(by='Mentions', ascending=False)


country_mentions_df


# Plot the frequency of country mentions
plt.figure(figsize=(12, 8))
sns.barplot(x='Mentions', y='Country', data=country_mentions_df, palette='coolwarm')
plt.title('Frequency of Country Mentions')
plt.xlabel('Number of Mentions')
plt.ylabel('Country')
plt.show()





# Plot the top 30 countries by mentions
top_30_countries = country_mentions_df.head(30)


top_30_countries


plt.figure(figsize=(12, 10))
sns.barplot(x='Mentions', y='Country', data=top_30_countries, palette='coolwarm')
plt.title('Top 30 Countries by Mentions')
plt.xlabel('Number of Mentions')
plt.ylabel('Country')
plt.show()











text_sent = TextBlob(str(tokenized_sent))


print(text_sent.sentiment)





# Sentiment output for a single sentence
polarity = 0.054724875093134825
subjectivity = 0.3751971939190071

# Data for plotting
scores = [polarity, subjectivity]
labels = ['Polarity', 'Subjectivity']

# Create a bar plot
plt.figure(figsize=(6, 4))
plt.bar(labels, scores, color=['blue', 'green'])
plt.title("Sentiment Analysis Scores")
plt.ylabel("Score Value")
plt.ylim(-1, 1)  # Setting y-axis to range from -1 to 1 for polarity and subjectivity

# Display the plot
plt.show()
