


# Importing Libraries
from textblob import TextBlob
import pandas as pd
import os
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib
import nltk
import re
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
from collections import Counter
sns.set()





# Creating Path
path = r'C:\Users\anush\20th_Century'


# Loading the twentieth-century data from the CSV file
countries_data = pd.read_csv(os.path.join(path, 'countries_list_20th_century_1.5.csv'), index_col = False)

# Displaying the first few rows to verify the content
countries_data.head()


# Dropping 'Unnamed: 0' Column
countries_data = countries_data.drop(columns=['Unnamed: 0'])
countries_data.head()





from nltk.tokenize import word_tokenize
from nltk.probability import FreqDist


# Tokenizing the country names
country_names = countries_data['country_name'].dropna()  # Dropping any missing values
tokenized_words = []


# Tokenizing each country name into words
for country in country_names:
    tokenized_words.extend(word_tokenize(country))


# Calculate the frequency distribution
freq_dist = FreqDist(tokenized_words)





# Get the 10 most common words
common_words = freq_dist.most_common(10)


common_words


# Split the words and their frequencies for plotting
words, frequencies = zip(*common_words)


# Create a bar chart
plt.figure(figsize=(10, 6))
plt.bar(words, frequencies)
plt.xlabel('Words')
plt.ylabel('Frequency')
plt.title('Top 10 Most Common Words in Country Names (20th Century)')
plt.xticks(rotation=45)
plt.show()





from nltk.corpus import stopwords
import string
import re


# Define stop words and punctuation
stop_words = set(stopwords.words('english'))
punctuation = set(string.punctuation)


# Extra words to remove
new_stopwords = ["And", "Then", "n", "t", "s", "The", "and", "of", "the", "republic's"]


# Tokenizing the country names into words
filtered_words = []
for country in country_names:
    words = word_tokenize(country)
    # Convert words to lowercase and remove stop words, punctuation, and possessives
    for word in words:
        cleaned_word = re.sub(r"'s$", "", word.lower())  # Remove possessive 's
        if cleaned_word and cleaned_word not in stop_words and cleaned_word not in punctuation and cleaned_word not in new_stopwords:
            filtered_words.append(cleaned_word)


# Remove punctuation from the text (without tokenizing yet)
sans_punc = ' '.join(filtered_words)  # Join words back to a string

# Tokenize again after removing punctuation
tokenized_word_2 = word_tokenize(sans_punc)


# Create a frequency distribution
dist_words_filter_2 = FreqDist(filtered_words)


# Get the 10 most common words
common_words_1 = dist_words_filter_2.most_common(10)
print(common_words_1)


# Split the words and their frequencies for plotting
words, frequencies = zip(*common_words_1)


# Create a bar chart
plt.figure(figsize=(10, 6))
plt.bar(words, frequencies)
plt.xlabel('Words')
plt.ylabel('Frequency')
plt.title('Top 10 Most Common Words in Country Names (20th Century) - No Stopwords or Punctuation')
plt.xticks(rotation=45)
plt.show()








# Create a TextBlob object from the tokenized words
text_blob = TextBlob(" ".join(tokenized_word_2))  # Join the filtered words into a single string

# Generate POS tags using TextBlob
tags_list = text_blob.tags

# Display the tags list
print(tags_list)





# Extract POS tags (second element in the tuple)
pos_tags = [tag[1] for tag in tags_list]

# Count the frequency of each POS tag
pos_counts = Counter(pos_tags)


# Get the 10 most common POS tags
top_10_pos = pos_counts.most_common(10)


top_10_pos


# Prepare the data for plotting
pos, frequencies = zip(*top_10_pos)





# Create a bar plot using Seaborn
plt.figure(figsize=(10, 6))
sns.barplot(x=list(pos), y=list(frequencies), palette="Blues_d")
plt.xlabel('POS Tags')
plt.ylabel('Frequency')
plt.title('Top 10 POS Tags in the Article')
plt.xticks(rotation=45)
plt.show()





# Convert tags_list into a DataFrame for easier processing
tags_df = pd.DataFrame(tags_list, columns=['Word', 'Word type'])

# Filter and count for Nouns (NN, NNS)
nouns_df = tags_df[(tags_df['Word type'] == "NN") | (tags_df['Word type'] == "NNS")]
nouns_count = nouns_df.groupby('Word').size().reset_index(name='Occurrences')
nouns_sorted = nouns_count.sort_values(by='Occurrences', ascending=False).head(15)

# Filter and count for Verbs (VB, VBD, VBG, VBN, VBP, VBZ)
verbs_df = tags_df[tags_df['Word type'].str.startswith("VB")]
verbs_count = verbs_df.groupby('Word').size().reset_index(name='Occurrences')
verbs_sorted = verbs_count.sort_values(by='Occurrences', ascending=False).head(15)

# Filter and count for Adjectives (JJ, JJR, JJS)
adjectives_df = tags_df[tags_df['Word type'].str.startswith("JJ")]
adjectives_count = adjectives_df.groupby('Word').size().reset_index(name='Occurrences')
adjectives_sorted = adjectives_count.sort_values(by='Occurrences', ascending=False).head(15)


nouns_sorted


verbs_sorted


adjectives_sorted


# Plotting the results
fig, axes = plt.subplots(3, 1, figsize=(10, 18))

# Plot for Nouns
sns.barplot(x='Occurrences', y='Word', data=nouns_sorted, ax=axes[0], palette='viridis')
axes[0].set_title('Top 15 Nouns by Occurrences')
axes[0].set_xlabel('Occurrences')
axes[0].set_ylabel('Nouns')

# Plot for Verbs
sns.barplot(x='Occurrences', y='Word', data=verbs_sorted, ax=axes[1], palette='coolwarm')
axes[1].set_title('Top 15 Verbs by Occurrences')
axes[1].set_xlabel('Occurrences')
axes[1].set_ylabel('Verbs')

# Plot for Adjectives
sns.barplot(x='Occurrences', y='Word', data=adjectives_sorted, ax=axes[2], palette='Blues')
axes[2].set_title('Top 15 Adjectives by Occurrences')
axes[2].set_xlabel('Occurrences')
axes[2].set_ylabel('Adjectives')

plt.tight_layout()
plt.show()








# Clean up the country names column and convert it to a list
countries_list = countries_data['country_name'].str.strip().str.lower().tolist()  # Convert 'country_name' column to lowercase list

# Convert the tokenized list into a single string
listToStr = ' '.join([str(elem).lower() for elem in tokenized_word_2])  # Join the list of words into a string and convert to lowercase


# Clean the tokenized words from unwanted characters and count occurrences
all_counts = Counter(re.sub(r'\W+', ' ', listToStr).split())  # Clean non-alphanumeric characters and split the text


# Step 5: Replace specific country name aliases if necessary
country_mentions = {country: all_counts.get(country, 0) for country in countries_list}  # Ensure no KeyError if country is not found


# Check a few tokenized words to ensure they match the format of country names
print(tokenized_word_2[:20])  # Print the first 20 tokenized words to inspect


# Convert the dictionary into a DataFrame for easier manipulation
df_countries = pd.DataFrame(list(country_mentions.items()), columns=["Country", "Times Mentioned"])

# Sort the DataFrame by the 'Times Mentioned' column in descending order
df_sorted_countries = df_countries.sort_values(by="Times Mentioned", ascending=False)


df_sorted_countries








# Step 2: Plot the frequency of mentions using a bar plot
plt.figure(figsize=(12, 6))  # Set the figure size
sns.barplot(x="Times Mentioned", y="Country", data=df_sorted_countries, palette="viridis")  # Create the bar plot

# Add plot labels and title
plt.title('Frequency of Country Mentions in the Text')  # Set the title of the plot
plt.xlabel('Times Mentioned')  # Label for the x-axis
plt.ylabel('Country')  # Label for the y-axis
plt.tight_layout()  # Adjust layout to avoid overlap
plt.show()  # Display the plot





# Sort the DataFrame by "Times Mentioned" in descending order and select the top 30 countries
top_countries = df_sorted_countries.sort_values(by="Times Mentioned", ascending=False).head(30)

# Plot the frequency of mentions using a horizontal bar plot
plt.figure(figsize=(12, 10))  # Set the figure size
sns.barplot(x="Times Mentioned", y="Country", data=top_countries, palette="viridis")  # Create the bar plot

# Add plot labels and title
plt.title('Top 30 Countries Mentioned in the Text')  # Set the title of the plot
plt.xlabel('Times Mentioned')  # Label for the x-axis
plt.ylabel('Country')  # Label for the y-axis
plt.tight_layout()  # Adjust layout to avoid overlap

# Display the plot
plt.show()


top_countries






